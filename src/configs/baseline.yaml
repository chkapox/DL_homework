defaults:
  - model: baseline
  - writer: wandb
  - metrics: example
  - datasets: example
  - dataloader: example
  - transforms: example
  - _self_

model:
  _target_: src.model.LCNN
  in_channels: 1
  dropout: 0.75
transforms:
  instance_transforms:
    fft:
      window_length: 1724
      hop_length: 0.0081
      window_type: blackman
      n_fft: 512
optimizer:
  _target_: torch.optim.AdamW
  lr: 1e-4
  weight_decay: 1e-4
lr_scheduler:
  _target_: torch.optim.lr_scheduler.StepLR
  gamma: 0.98
  step_size: ${trainer.epoch_len}
loss_function:
  _target_: src.loss.example.ExampleLoss
  in_features: 128
  num_classes: 2
  m: 4
  s: 30.0
trainer:
  monitor: "min val_EER"
  log_step: 50
  n_epochs: 15
  epoch_len: 600
  device_tensors: ["data_object", "labels"]
  resume_from: null
  device: auto
  override: False
  save_period: 3
  early_stop: 10
  save_dir: "Q://deeplearn"
  seed: 1